{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66d3fb58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sale_date</th>\n",
       "      <th>sale_price</th>\n",
       "      <th>sale_nbr</th>\n",
       "      <th>sale_warning</th>\n",
       "      <th>join_status</th>\n",
       "      <th>join_year</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>area</th>\n",
       "      <th>city</th>\n",
       "      <th>...</th>\n",
       "      <th>view_olympics</th>\n",
       "      <th>view_cascades</th>\n",
       "      <th>view_territorial</th>\n",
       "      <th>view_skyline</th>\n",
       "      <th>view_sound</th>\n",
       "      <th>view_lakewash</th>\n",
       "      <th>view_lakesamm</th>\n",
       "      <th>view_otherwater</th>\n",
       "      <th>view_other</th>\n",
       "      <th>submarket</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-11-15</td>\n",
       "      <td>236000</td>\n",
       "      <td>2.0</td>\n",
       "      <td></td>\n",
       "      <td>nochg</td>\n",
       "      <td>2025</td>\n",
       "      <td>47.2917</td>\n",
       "      <td>-122.3658</td>\n",
       "      <td>53</td>\n",
       "      <td>FEDERAL WAY</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999-01-15</td>\n",
       "      <td>313300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>nochg</td>\n",
       "      <td>2025</td>\n",
       "      <td>47.6531</td>\n",
       "      <td>-122.1996</td>\n",
       "      <td>74</td>\n",
       "      <td>KIRKLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-08-15</td>\n",
       "      <td>341000</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>nochg</td>\n",
       "      <td>2025</td>\n",
       "      <td>47.4733</td>\n",
       "      <td>-122.1901</td>\n",
       "      <td>30</td>\n",
       "      <td>RENTON</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999-12-15</td>\n",
       "      <td>267000</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>nochg</td>\n",
       "      <td>2025</td>\n",
       "      <td>47.4739</td>\n",
       "      <td>-122.3295</td>\n",
       "      <td>96</td>\n",
       "      <td>BURIEN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-07-15</td>\n",
       "      <td>1650000</td>\n",
       "      <td>2.0</td>\n",
       "      <td></td>\n",
       "      <td>miss99</td>\n",
       "      <td>2025</td>\n",
       "      <td>47.7516</td>\n",
       "      <td>-122.1222</td>\n",
       "      <td>36</td>\n",
       "      <td>KING COUNTY</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>2000-08-15</td>\n",
       "      <td>277500</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>nochg</td>\n",
       "      <td>2025</td>\n",
       "      <td>47.5503</td>\n",
       "      <td>-122.0285</td>\n",
       "      <td>69</td>\n",
       "      <td>ISSAQUAH</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>2019-07-15</td>\n",
       "      <td>1296000</td>\n",
       "      <td>2.0</td>\n",
       "      <td></td>\n",
       "      <td>new</td>\n",
       "      <td>2025</td>\n",
       "      <td>47.6789</td>\n",
       "      <td>-122.1164</td>\n",
       "      <td>72</td>\n",
       "      <td>REDMOND</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>845000</td>\n",
       "      <td>2.0</td>\n",
       "      <td></td>\n",
       "      <td>new</td>\n",
       "      <td>2025</td>\n",
       "      <td>47.6939</td>\n",
       "      <td>-122.3542</td>\n",
       "      <td>6</td>\n",
       "      <td>SEATTLE</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>890000</td>\n",
       "      <td>2.0</td>\n",
       "      <td></td>\n",
       "      <td>nochg</td>\n",
       "      <td>2025</td>\n",
       "      <td>47.6433</td>\n",
       "      <td>-122.0613</td>\n",
       "      <td>35</td>\n",
       "      <td>SAMMAMISH</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>2024-06-15</td>\n",
       "      <td>799000</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>new</td>\n",
       "      <td>2025</td>\n",
       "      <td>47.5806</td>\n",
       "      <td>-122.3881</td>\n",
       "      <td>48</td>\n",
       "      <td>SEATTLE</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sale_date  sale_price  sale_nbr sale_warning join_status  join_year  \\\n",
       "id                                                                             \n",
       "0       2014-11-15      236000       2.0                    nochg       2025   \n",
       "1       1999-01-15      313300       NaN          26        nochg       2025   \n",
       "2       2006-08-15      341000       1.0                    nochg       2025   \n",
       "3       1999-12-15      267000       1.0                    nochg       2025   \n",
       "4       2018-07-15     1650000       2.0                   miss99       2025   \n",
       "...            ...         ...       ...          ...         ...        ...   \n",
       "199995  2000-08-15      277500       1.0                    nochg       2025   \n",
       "199996  2019-07-15     1296000       2.0                      new       2025   \n",
       "199997  2018-06-15      845000       2.0                      new       2025   \n",
       "199998  2018-06-15      890000       2.0                    nochg       2025   \n",
       "199999  2024-06-15      799000       NaN                      new       2025   \n",
       "\n",
       "        latitude  longitude  area         city  ... view_olympics  \\\n",
       "id                                              ...                 \n",
       "0        47.2917  -122.3658    53  FEDERAL WAY  ...             0   \n",
       "1        47.6531  -122.1996    74     KIRKLAND  ...             0   \n",
       "2        47.4733  -122.1901    30       RENTON  ...             0   \n",
       "3        47.4739  -122.3295    96       BURIEN  ...             0   \n",
       "4        47.7516  -122.1222    36  KING COUNTY  ...             0   \n",
       "...          ...        ...   ...          ...  ...           ...   \n",
       "199995   47.5503  -122.0285    69     ISSAQUAH  ...             0   \n",
       "199996   47.6789  -122.1164    72      REDMOND  ...             0   \n",
       "199997   47.6939  -122.3542     6      SEATTLE  ...             0   \n",
       "199998   47.6433  -122.0613    35    SAMMAMISH  ...             0   \n",
       "199999   47.5806  -122.3881    48      SEATTLE  ...             0   \n",
       "\n",
       "       view_cascades  view_territorial  view_skyline  view_sound  \\\n",
       "id                                                                 \n",
       "0                  0                 0             0           0   \n",
       "1                  0                 0             0           0   \n",
       "2                  0                 0             0           0   \n",
       "3                  0                 0             0           0   \n",
       "4                  0                 0             0           0   \n",
       "...              ...               ...           ...         ...   \n",
       "199995             0                 0             0           0   \n",
       "199996             0                 0             0           0   \n",
       "199997             0                 0             0           0   \n",
       "199998             0                 0             0           0   \n",
       "199999             0                 0             0           0   \n",
       "\n",
       "        view_lakewash  view_lakesamm  view_otherwater  view_other  submarket  \n",
       "id                                                                            \n",
       "0                   0              0                0           0          I  \n",
       "1                   1              0                0           0          Q  \n",
       "2                   0              0                0           0          K  \n",
       "3                   0              0                0           0          G  \n",
       "4                   0              0                0           0          P  \n",
       "...               ...            ...              ...         ...        ...  \n",
       "199995              0              0                0           0          O  \n",
       "199996              0              0                0           0          P  \n",
       "199997              0              0                0           0          B  \n",
       "199998              0              0                0           0          O  \n",
       "199999              0              0                0           0          F  \n",
       "\n",
       "[200000 rows x 46 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/dataset.csv', index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3b079b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.000000e+05\n",
       "mean     5.841495e+05\n",
       "std      4.170595e+05\n",
       "min      5.029300e+04\n",
       "25%      3.050000e+05\n",
       "50%      4.599500e+05\n",
       "75%      7.249500e+05\n",
       "max      2.999950e+06\n",
       "Name: sale_price, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sale_price'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c7dc5c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['sale_price'].hist(bins=50, figsize=(10, 5), grid=False, color='blue', edgecolor='black', alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70390627",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/clementcouchevellou/Documents/Personal projects/prediction_interval_comp_II-house_price/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train, val = TabularDataset(train_df), TabularDataset(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f37c8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"autogluon_models\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.11.11\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 24.5.0: Tue Apr 22 19:54:43 PDT 2025; root:xnu-11417.121.6~2/RELEASE_ARM64_T8132\n",
      "CPU Count:          10\n",
      "Memory Avail:       14.78 GB / 32.00 GB (46.2%)\n",
      "Disk Space Avail:   128.03 GB / 926.35 GB (13.8%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 300s of the 1200s of remaining time (25%).\n",
      "2025-07-14 10:08:38,672\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2025-07-14 10:08:39,537\tINFO worker.py:1843 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\t\tContext path: \"/Users/clementcouchevellou/Documents/Personal projects/prediction_interval_comp_II-house_price/autogluon_models/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m /Users/clementcouchevellou/Documents/Personal projects/prediction_interval_comp_II-house_price/.venv/lib/python3.11/site-packages/autogluon/common/utils/utils.py:97: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m   import pkg_resources\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m Beginning AutoGluon training ... Time limit = 299s\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m AutoGluon will save models to \"/Users/clementcouchevellou/Documents/Personal projects/prediction_interval_comp_II-house_price/autogluon_models/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m Train Data Rows:    113777\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m Train Data Columns: 45\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m Label Column:       sale_price\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m Problem Type:       quantile\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \tAvailable Memory:                    14593.21 MB\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \tTrain Data (Original)  Memory Usage: 81.43 MB (0.6% of available memory)\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t\tFitting DatetimeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t\tFitting TextSpecialFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t\t\tFitting BinnedFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t\tFitting TextNgramFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t\t\tFitting CountVectorizer for text features: ['subdivision']\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t\t\tCountVectorizer fit with vocabulary size = 198\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t\t('float', [])                      :  4 | ['sale_nbr', 'latitude', 'longitude', 'stories']\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t\t('int', [])                        : 34 | ['join_year', 'area', 'present_use', 'land_val', 'imp_val', ...]\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t\t('object', [])                     :  5 | ['sale_warning', 'join_status', 'city', 'zoning', 'submarket']\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t\t('object', ['datetime_as_object']) :  1 | ['sale_date']\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t\t('object', ['text'])               :  1 | ['subdivision']\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t\t('category', [])                    :   5 | ['sale_warning', 'join_status', 'city', 'zoning', 'submarket']\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t\t('category', ['text_as_category'])  :   1 | ['subdivision']\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t\t('float', [])                       :   4 | ['sale_nbr', 'latitude', 'longitude', 'stories']\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t\t('int', [])                         :  31 | ['area', 'present_use', 'land_val', 'imp_val', 'year_built', ...]\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t\t('int', ['binned', 'text_special']) :  13 | ['subdivision.char_count', 'subdivision.word_count', 'subdivision.capital_ratio', 'subdivision.digit_ratio', 'subdivision.special_ratio', ...]\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t\t('int', ['bool'])                   :   3 | ['join_year', 'golf', 'greenbelt']\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t\t('int', ['datetime_as_int'])        :   4 | ['sale_date', 'sale_date.year', 'sale_date.month', 'sale_date.dayofweek']\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t\t('int', ['text_ngram'])             : 192 | ['__nlp__.01', '__nlp__.02', '__nlp__.03', '__nlp__.04', '__nlp__.05', ...]\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t2.1s = Fit runtime\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t45 features in original data used to generate 253 features in processed data.\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \tTrain Data (Processed) Memory Usage: 78.13 MB (0.5% of available memory)\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m Data preprocessing and feature engineering runtime = 2.18s ...\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m Fitting 96 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 197.52s of the 296.35s of remaining time.\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=10, gpus=0, memory=3.74%)\n",
      "\u001b[36m(_ray_fit pid=98132)\u001b[0m \tRan out of time, early stopping on iteration 1005. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=98132)\u001b[0m \t[1005]\tvalid_set's quantile: 7981.62\n",
      "\u001b[36m(_ray_fit pid=98132)\u001b[0m \tRan out of time, early stopping on iteration 950. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=98132)\u001b[0m \t[950]\tvalid_set's quantile: 30060.8\n",
      "\u001b[36m(_ray_fit pid=98132)\u001b[0m \tRan out of time, early stopping on iteration 972. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=98132)\u001b[0m \t[971]\tvalid_set's quantile: 9788.26\n",
      "\u001b[36m(_ray_fit pid=98198)\u001b[0m \tRan out of time, early stopping on iteration 973. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=98198)\u001b[0m \t[973]\tvalid_set's quantile: 8060.68\n",
      "\u001b[36m(_ray_fit pid=98198)\u001b[0m \tRan out of time, early stopping on iteration 930. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=98198)\u001b[0m \t[930]\tvalid_set's quantile: 29528.5\n",
      "\u001b[36m(_ray_fit pid=98198)\u001b[0m \tRan out of time, early stopping on iteration 964. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=98198)\u001b[0m \t[961]\tvalid_set's quantile: 10091\n",
      "\u001b[36m(_ray_fit pid=98267)\u001b[0m \tRan out of time, early stopping on iteration 984. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=98267)\u001b[0m \t[982]\tvalid_set's quantile: 8142.97\n",
      "\u001b[36m(_ray_fit pid=98267)\u001b[0m \tRan out of time, early stopping on iteration 932. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=98267)\u001b[0m \t[932]\tvalid_set's quantile: 30108.3\n",
      "\u001b[36m(_ray_fit pid=98267)\u001b[0m \tRan out of time, early stopping on iteration 962. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=98267)\u001b[0m \t[961]\tvalid_set's quantile: 9749.78\n",
      "\u001b[36m(_ray_fit pid=98343)\u001b[0m \tRan out of time, early stopping on iteration 973. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=98343)\u001b[0m \t[973]\tvalid_set's quantile: 8234.15\n",
      "\u001b[36m(_ray_fit pid=98343)\u001b[0m \tRan out of time, early stopping on iteration 913. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=98343)\u001b[0m \t[913]\tvalid_set's quantile: 30726.8\n",
      "\u001b[36m(_ray_fit pid=98343)\u001b[0m \tRan out of time, early stopping on iteration 1016. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=98343)\u001b[0m \t[1015]\tvalid_set's quantile: 10337.5\n",
      "\u001b[36m(_ray_fit pid=98420)\u001b[0m \tRan out of time, early stopping on iteration 1025. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=98420)\u001b[0m \t[1023]\tvalid_set's quantile: 7998.7\n",
      "\u001b[36m(_ray_fit pid=98420)\u001b[0m \tRan out of time, early stopping on iteration 982. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=98420)\u001b[0m \t[982]\tvalid_set's quantile: 29582.3\n",
      "\u001b[36m(_ray_fit pid=98420)\u001b[0m \tRan out of time, early stopping on iteration 1031. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=98420)\u001b[0m \t[1031]\tvalid_set's quantile: 9566.74\n",
      "\u001b[36m(_ray_fit pid=98493)\u001b[0m \tRan out of time, early stopping on iteration 1033. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=98493)\u001b[0m \t[1030]\tvalid_set's quantile: 7995.53\n",
      "\u001b[36m(_ray_fit pid=98493)\u001b[0m \tRan out of time, early stopping on iteration 978. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=98493)\u001b[0m \t[978]\tvalid_set's quantile: 29829\n",
      "\u001b[36m(_ray_fit pid=98493)\u001b[0m \tRan out of time, early stopping on iteration 1025. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=98493)\u001b[0m \t[1025]\tvalid_set's quantile: 9758.12\n",
      "\u001b[36m(_ray_fit pid=98560)\u001b[0m \tRan out of time, early stopping on iteration 1028. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=98560)\u001b[0m \t[1028]\tvalid_set's quantile: 8175.92\n",
      "\u001b[36m(_ray_fit pid=98560)\u001b[0m \tRan out of time, early stopping on iteration 950. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=98560)\u001b[0m \t[950]\tvalid_set's quantile: 30046.1\n",
      "\u001b[36m(_ray_fit pid=98560)\u001b[0m \tRan out of time, early stopping on iteration 959. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=98560)\u001b[0m \t[953]\tvalid_set's quantile: 9739.78\n",
      "\u001b[36m(_ray_fit pid=98630)\u001b[0m \tRan out of time, early stopping on iteration 980. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=98630)\u001b[0m \t[979]\tvalid_set's quantile: 8175.67\n",
      "\u001b[36m(_ray_fit pid=98630)\u001b[0m \tRan out of time, early stopping on iteration 969. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=98630)\u001b[0m \t[969]\tvalid_set's quantile: 30269.8\n",
      "\u001b[36m(_ray_fit pid=98630)\u001b[0m \tRan out of time, early stopping on iteration 1011. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=98630)\u001b[0m \t[1007]\tvalid_set's quantile: 9991.9\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t-15997.4916\t = Validation score   (-pinball_loss)\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t168.48s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t3.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 26.97s of the 125.80s of remaining time.\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=10, gpus=0, memory=3.72%)\n",
      "\u001b[36m(_ray_fit pid=98706)\u001b[0m \tRan out of time, early stopping on iteration 90. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=98706)\u001b[0m \t[90]\tvalid_set's quantile: 13447.1\n",
      "\u001b[36m(_ray_fit pid=98706)\u001b[0m \tRan out of time, early stopping on iteration 83. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=98706)\u001b[0m \t[83]\tvalid_set's quantile: 40933.5\n",
      "\u001b[36m(_ray_fit pid=98706)\u001b[0m \tRan out of time, early stopping on iteration 91. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=98706)\u001b[0m \t[91]\tvalid_set's quantile: 13827.5\n",
      "\u001b[36m(_ray_fit pid=98717)\u001b[0m \tRan out of time, early stopping on iteration 95. Best iteration is:\u001b[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=98717)\u001b[0m \t[95]\tvalid_set's quantile: 13690.4\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=98749)\u001b[0m \tRan out of time, early stopping on iteration 93. Best iteration is:\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=98749)\u001b[0m \t[93]\tvalid_set's quantile: 13557.5\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=98760)\u001b[0m \tRan out of time, early stopping on iteration 97. Best iteration is:\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=98760)\u001b[0m \t[97]\tvalid_set's quantile: 13190.2\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=98782)\u001b[0m \tRan out of time, early stopping on iteration 93. Best iteration is:\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=98782)\u001b[0m \t[93]\tvalid_set's quantile: 13697.8\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=98793)\u001b[0m \tRan out of time, early stopping on iteration 94. Best iteration is:\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=98793)\u001b[0m \t[94]\tvalid_set's quantile: 13717.3\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t-22600.9898\t = Validation score   (-pinball_loss)\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t28.74s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t0.36s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 296.35s of the 95.95s of remaining time.\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t-15997.4916\t = Validation score   (-pinball_loss)\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t0.26s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m Fitting 96 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 95.68s of the 95.66s of remaining time.\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=10, gpus=0, memory=3.90%)\n",
      "\u001b[36m(_ray_fit pid=98809)\u001b[0m \tRan out of time, early stopping on iteration 429. Best iteration is:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=98809)\u001b[0m \t[429]\tvalid_set's quantile: 28827.9\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=98847)\u001b[0m \tRan out of time, early stopping on iteration 460. Best iteration is:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=98847)\u001b[0m \t[460]\tvalid_set's quantile: 7635.6\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=98847)\u001b[0m \tRan out of time, early stopping on iteration 449. Best iteration is:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=98847)\u001b[0m \t[448]\tvalid_set's quantile: 9221.62\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=98883)\u001b[0m \tRan out of time, early stopping on iteration 421. Best iteration is:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=98883)\u001b[0m \t[420]\tvalid_set's quantile: 29378.8\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=98924)\u001b[0m \tRan out of time, early stopping on iteration 467. Best iteration is:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=98924)\u001b[0m \t[463]\tvalid_set's quantile: 7915.48\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=98924)\u001b[0m \tRan out of time, early stopping on iteration 434. Best iteration is:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=98924)\u001b[0m \t[425]\tvalid_set's quantile: 9343.96\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=98964)\u001b[0m \tRan out of time, early stopping on iteration 415. Best iteration is:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=98964)\u001b[0m \t[415]\tvalid_set's quantile: 29128.9\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=99005)\u001b[0m \tRan out of time, early stopping on iteration 465. Best iteration is:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=99005)\u001b[0m \t[441]\tvalid_set's quantile: 7563.07\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=99005)\u001b[0m \tRan out of time, early stopping on iteration 456. Best iteration is:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=99005)\u001b[0m \t[456]\tvalid_set's quantile: 9084.29\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=99041)\u001b[0m \tRan out of time, early stopping on iteration 424. Best iteration is:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=99041)\u001b[0m \t[424]\tvalid_set's quantile: 29091.2\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=99077)\u001b[0m \tRan out of time, early stopping on iteration 395. Best iteration is:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=99077)\u001b[0m \t[394]\tvalid_set's quantile: 7570.73\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=99077)\u001b[0m \tRan out of time, early stopping on iteration 472. Best iteration is:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=99077)\u001b[0m \t[426]\tvalid_set's quantile: 9526.77\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t-15417.1424\t = Validation score   (-pinball_loss)\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t85.01s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t1.35s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 9.52s of the 9.51s of remaining time.\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=10, gpus=0, memory=3.86%)\n",
      "\u001b[36m(_ray_fit pid=99120)\u001b[0m \tRan out of time, early stopping on iteration 9. Best iteration is:\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=99120)\u001b[0m \t[9]\tvalid_set's quantile: 19558.1\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=99138)\u001b[0m \tRan out of time, early stopping on iteration 8. Best iteration is:\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=99138)\u001b[0m \t[8]\tvalid_set's quantile: 19435.5\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t-57974.0171\t = Validation score   (-pinball_loss)\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t14.6s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t0.15s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 296.35s of the -6.19s of remaining time.\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L2': 0.824, 'LightGBMXT_BAG_L1': 0.176}\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t-15386.7375\t = Validation score   (-pinball_loss)\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t0.47s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m AutoGluon training complete, total runtime = 305.23s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 2976.1 rows/s (14223 batch size)\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/clementcouchevellou/Documents/Personal projects/prediction_interval_comp_II-house_price/autogluon_models/ds_sub_fit/sub_fit_ho\")\n",
      "\u001b[36m(_dystack pid=98102)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "\u001b[36m(_ray_fit pid=99150)\u001b[0m \tRan out of time, early stopping on iteration 10. Best iteration is:\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=99150)\u001b[0m \t[10]\tvalid_set's quantile: 43191.3\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                 model  score_holdout     score_val   eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0    LightGBMXT_BAG_L2  -14726.848121 -15417.142438  pinball_loss        5.551476       4.778336  282.232458                 1.562764                1.352122          85.010429            2       True          4\n",
      "1  WeightedEnsemble_L3  -14766.298263 -15386.737514  pinball_loss        5.552600       4.784398  282.706773                 0.001124                0.006062           0.474315            3       True          6\n",
      "2  WeightedEnsemble_L2  -15315.132285 -15997.491632  pinball_loss        3.486620       3.076863  168.739130                 0.001388                0.005759           0.261278            2       True          3\n",
      "3    LightGBMXT_BAG_L1  -15315.132285 -15997.491632  pinball_loss        3.485232       3.071104  168.477852                 3.485232                3.071104         168.477852            1       True          1\n",
      "4      LightGBM_BAG_L1  -22176.397537 -22600.989757  pinball_loss        0.503480       0.355110   28.744177                 0.503480                0.355110          28.744177            1       True          2\n",
      "5      LightGBM_BAG_L2  -56892.139128 -57974.017084  pinball_loss        4.219418       3.578098  211.819426                 0.230706                0.151884          14.597397            2       True          5\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t313s\t = DyStack   runtime |\t887s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "/Users/clementcouchevellou/Documents/Personal projects/prediction_interval_comp_II-house_price/.venv/lib/python3.11/site-packages/autogluon/common/utils/utils.py:97: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "Beginning AutoGluon training ... Time limit = 887s\n",
      "AutoGluon will save models to \"/Users/clementcouchevellou/Documents/Personal projects/prediction_interval_comp_II-house_price/autogluon_models\"\n",
      "Train Data Rows:    128000\n",
      "Train Data Columns: 45\n",
      "Label Column:       sale_price\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    15317.14 MB\n",
      "\tTrain Data (Original)  Memory Usage: 91.64 MB (0.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['subdivision']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 202\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                      :  4 | ['sale_nbr', 'latitude', 'longitude', 'stories']\n",
      "\t\t('int', [])                        : 34 | ['join_year', 'area', 'present_use', 'land_val', 'imp_val', ...]\n",
      "\t\t('object', [])                     :  5 | ['sale_warning', 'join_status', 'city', 'zoning', 'submarket']\n",
      "\t\t('object', ['datetime_as_object']) :  1 | ['sale_date']\n",
      "\t\t('object', ['text'])               :  1 | ['subdivision']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :   5 | ['sale_warning', 'join_status', 'city', 'zoning', 'submarket']\n",
      "\t\t('category', ['text_as_category'])  :   1 | ['subdivision']\n",
      "\t\t('float', [])                       :   4 | ['sale_nbr', 'latitude', 'longitude', 'stories']\n",
      "\t\t('int', [])                         :  31 | ['area', 'present_use', 'land_val', 'imp_val', 'year_built', ...]\n",
      "\t\t('int', ['binned', 'text_special']) :  13 | ['subdivision.char_count', 'subdivision.word_count', 'subdivision.capital_ratio', 'subdivision.digit_ratio', 'subdivision.special_ratio', ...]\n",
      "\t\t('int', ['bool'])                   :   3 | ['join_year', 'golf', 'greenbelt']\n",
      "\t\t('int', ['datetime_as_int'])        :   4 | ['sale_date', 'sale_date.year', 'sale_date.month', 'sale_date.dayofweek']\n",
      "\t\t('int', ['text_ngram'])             : 195 | ['__nlp__.01', '__nlp__.02', '__nlp__.03', '__nlp__.04', '__nlp__.05', ...]\n",
      "\t2.5s = Fit runtime\n",
      "\t45 features in original data used to generate 256 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 88.63 MB (0.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.61s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 96 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 589.14s of the 883.93s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=10, gpus=0, memory=4.04%)\n",
      "\t-15450.075\t = Validation score   (-pinball_loss)\n",
      "\t447.65s\t = Training   runtime\n",
      "\t9.27s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 138.70s of the 433.49s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=10, gpus=0, memory=3.96%)\n",
      "\t-16948.1515\t = Validation score   (-pinball_loss)\n",
      "\t121.64s\t = Training   runtime\n",
      "\t2.32s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 15.61s of the 310.40s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=10, gpus=0, memory=1.13%)\n",
      "\t-17404.7213\t = Validation score   (-pinball_loss)\n",
      "\t1943.95s\t = Training   runtime\n",
      "\t69.23s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the -1644.07s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.739, 'RandomForestMSE_BAG_L1': 0.217, 'LightGBM_BAG_L1': 0.043}\n",
      "\t-15137.9353\t = Validation score   (-pinball_loss)\n",
      "\t0.45s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 96 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the -1644.58s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.739, 'RandomForestMSE_BAG_L1': 0.217, 'LightGBM_BAG_L1': 0.043}\n",
      "\t-15137.9353\t = Validation score   (-pinball_loss)\n",
      "\t0.42s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2531.59s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 198.0 rows/s (16000 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/clementcouchevellou/Documents/Personal projects/prediction_interval_comp_II-house_price/autogluon_models\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(\n",
    "    label='sale_price',\n",
    "    problem_type='quantile',\n",
    "    quantile_levels=[0.05, 0.5, 0.95],\n",
    "    path='autogluon_models',\n",
    "    eval_metric='pinball_loss',\n",
    "    verbosity=2,\n",
    ").fit(\n",
    "    train.sample(frac=0.8, random_state=42),\n",
    "    #hyperparameters='light',\n",
    "    presets='best_quality',\n",
    "    dynamic_stacking=True,\n",
    "    calibrate_decision_threshold='auto',\n",
    "    ag_args_fit={\n",
    "        'num_cpus': 10,\n",
    "        #'ag.max_memory_usage_ratio': 3.0,\n",
    "    },\n",
    "    time_limit=1200,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "227e5cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                    model     score_val   eval_metric  pred_time_val     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0     WeightedEnsemble_L3 -15137.935314  pinball_loss      80.823108  2513.658417                0.006763           0.417849            3       True          5\n",
      "1     WeightedEnsemble_L2 -15137.935314  pinball_loss      80.823204  2513.693185                0.006859           0.452617            2       True          4\n",
      "2       LightGBMXT_BAG_L1 -15450.075030  pinball_loss       9.265532   447.647278                9.265532         447.647278            1       True          1\n",
      "3         LightGBM_BAG_L1 -16948.151452  pinball_loss       2.318067   121.642115                2.318067         121.642115            1       True          2\n",
      "4  RandomForestMSE_BAG_L1 -17404.721281  pinball_loss      69.232747  1943.951175               69.232747        1943.951175            1       True          3\n",
      "Number of models trained: 5\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_LGB', 'WeightedEnsembleModel', 'StackerEnsembleModel_RF'}\n",
      "Bagging used: True  (with 8 folds)\n",
      "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', [])                    :   5 | ['sale_warning', 'join_status', 'city', 'zoning', 'submarket']\n",
      "('category', ['text_as_category'])  :   1 | ['subdivision']\n",
      "('float', [])                       :   4 | ['sale_nbr', 'latitude', 'longitude', 'stories']\n",
      "('int', [])                         :  31 | ['area', 'present_use', 'land_val', 'imp_val', 'year_built', ...]\n",
      "('int', ['binned', 'text_special']) :  13 | ['subdivision.char_count', 'subdivision.word_count', 'subdivision.capital_ratio', 'subdivision.digit_ratio', 'subdivision.special_ratio', ...]\n",
      "('int', ['bool'])                   :   3 | ['join_year', 'golf', 'greenbelt']\n",
      "('int', ['datetime_as_int'])        :   4 | ['sale_date', 'sale_date.year', 'sale_date.month', 'sale_date.dayofweek']\n",
      "('int', ['text_ngram'])             : 195 | ['__nlp__.01', '__nlp__.02', '__nlp__.03', '__nlp__.04', '__nlp__.05', ...]\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/clementcouchevellou/Documents/Personal projects/prediction_interval_comp_II-house_price/.venv/lib/python3.11/site-packages/autogluon/core/utils/plots.py:169: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"\n",
      "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_types': {'LightGBMXT_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'LightGBM_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'RandomForestMSE_BAG_L1': 'StackerEnsembleModel_RF',\n",
       "  'WeightedEnsemble_L2': 'WeightedEnsembleModel',\n",
       "  'WeightedEnsemble_L3': 'WeightedEnsembleModel'},\n",
       " 'model_performance': {'LightGBMXT_BAG_L1': np.float64(-15450.075029562557),\n",
       "  'LightGBM_BAG_L1': np.float64(-16948.151451723006),\n",
       "  'RandomForestMSE_BAG_L1': np.float64(-17404.721281258597),\n",
       "  'WeightedEnsemble_L2': np.float64(-15137.935314224107),\n",
       "  'WeightedEnsemble_L3': np.float64(-15137.935314224107)},\n",
       " 'model_best': 'WeightedEnsemble_L2',\n",
       " 'model_paths': {'LightGBMXT_BAG_L1': ['LightGBMXT_BAG_L1'],\n",
       "  'LightGBM_BAG_L1': ['LightGBM_BAG_L1'],\n",
       "  'RandomForestMSE_BAG_L1': ['RandomForestMSE_BAG_L1'],\n",
       "  'WeightedEnsemble_L2': ['WeightedEnsemble_L2'],\n",
       "  'WeightedEnsemble_L3': ['WeightedEnsemble_L3']},\n",
       " 'model_fit_times': {'LightGBMXT_BAG_L1': 447.64727783203125,\n",
       "  'LightGBM_BAG_L1': 121.64211511611938,\n",
       "  'RandomForestMSE_BAG_L1': 1943.9511749744415,\n",
       "  'WeightedEnsemble_L2': 0.45261693000793457,\n",
       "  'WeightedEnsemble_L3': 0.417849063873291},\n",
       " 'model_pred_times': {'LightGBMXT_BAG_L1': 9.265531539916992,\n",
       "  'LightGBM_BAG_L1': 2.3180670738220215,\n",
       "  'RandomForestMSE_BAG_L1': 69.23274683952332,\n",
       "  'WeightedEnsemble_L2': 0.00685882568359375,\n",
       "  'WeightedEnsemble_L3': 0.006762981414794922},\n",
       " 'num_bag_folds': 8,\n",
       " 'max_stack_level': 3,\n",
       " 'num_quantiles': 3,\n",
       " 'model_hyperparams': {'LightGBMXT_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'stratify': 'auto',\n",
       "   'bin': 'auto',\n",
       "   'n_bins': None},\n",
       "  'LightGBM_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'stratify': 'auto',\n",
       "   'bin': 'auto',\n",
       "   'n_bins': None},\n",
       "  'RandomForestMSE_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'stratify': 'auto',\n",
       "   'bin': 'auto',\n",
       "   'n_bins': None},\n",
       "  'WeightedEnsemble_L2': {'use_orig_features': False,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'stratify': 'auto',\n",
       "   'bin': 'auto',\n",
       "   'n_bins': None},\n",
       "  'WeightedEnsemble_L3': {'use_orig_features': False,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'stratify': 'auto',\n",
       "   'bin': 'auto',\n",
       "   'n_bins': None}},\n",
       " 'leaderboard':                     model     score_val   eval_metric  pred_time_val  \\\n",
       " 0     WeightedEnsemble_L3 -15137.935314  pinball_loss      80.823108   \n",
       " 1     WeightedEnsemble_L2 -15137.935314  pinball_loss      80.823204   \n",
       " 2       LightGBMXT_BAG_L1 -15450.075030  pinball_loss       9.265532   \n",
       " 3         LightGBM_BAG_L1 -16948.151452  pinball_loss       2.318067   \n",
       " 4  RandomForestMSE_BAG_L1 -17404.721281  pinball_loss      69.232747   \n",
       " \n",
       "       fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       " 0  2513.658417                0.006763           0.417849            3   \n",
       " 1  2513.693185                0.006859           0.452617            2   \n",
       " 2   447.647278                9.265532         447.647278            1   \n",
       " 3   121.642115                2.318067         121.642115            1   \n",
       " 4  1943.951175               69.232747        1943.951175            1   \n",
       " \n",
       "    can_infer  fit_order  \n",
       " 0       True          5  \n",
       " 1       True          4  \n",
       " 2       True          1  \n",
       " 3       True          2  \n",
       " 4       True          3  }"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e7078d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from autogluon.core.metrics import make_scorer\n",
    "\n",
    "alpha = 0.1\n",
    "\n",
    "def winkler_score(y_true, y_pred, quantile_levels=None, **kwargs):\n",
    "    if hasattr(y_pred, \"values\"):\n",
    "        y_pred = y_pred.values\n",
    "    if quantile_levels is not None:\n",
    "        lower_idx = np.argmin(np.abs(np.array(quantile_levels) - 0.05))\n",
    "        upper_idx = np.argmin(np.abs(np.array(quantile_levels) - 0.95))\n",
    "        l, u = y_pred[:, lower_idx], y_pred[:, upper_idx]\n",
    "    else:\n",
    "        l, u = y_pred[:, 0], y_pred[:, 1]\n",
    "    y_true = np.array(y_true)\n",
    "    score = np.where(\n",
    "        y_true < l,\n",
    "        (u - l) + 2/alpha * (l - y_true),\n",
    "        np.where(\n",
    "            y_true > u,\n",
    "            (u - l) + 2/alpha * (y_true - u),\n",
    "            u - l\n",
    "        )\n",
    "    )\n",
    "    return score.mean()\n",
    "\n",
    "winkler = make_scorer(\n",
    "    name='winkler',\n",
    "    score_func=winkler_score,\n",
    "    greater_is_better=False,\n",
    "    needs_quantile=True,\n",
    "    optimum=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6b5bf4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>winkler</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-14835.534623</td>\n",
       "      <td>-333325.959380</td>\n",
       "      <td>-15137.935314</td>\n",
       "      <td>pinball_loss</td>\n",
       "      <td>243.903204</td>\n",
       "      <td>80.823204</td>\n",
       "      <td>2513.693185</td>\n",
       "      <td>0.006198</td>\n",
       "      <td>0.006859</td>\n",
       "      <td>0.452617</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>-14836.838373</td>\n",
       "      <td>-333404.184288</td>\n",
       "      <td>-15137.935314</td>\n",
       "      <td>pinball_loss</td>\n",
       "      <td>243.900194</td>\n",
       "      <td>80.823108</td>\n",
       "      <td>2513.658417</td>\n",
       "      <td>0.003188</td>\n",
       "      <td>0.006763</td>\n",
       "      <td>0.417849</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>-14961.281246</td>\n",
       "      <td>-340636.465662</td>\n",
       "      <td>-15450.075030</td>\n",
       "      <td>pinball_loss</td>\n",
       "      <td>55.001518</td>\n",
       "      <td>9.265532</td>\n",
       "      <td>447.647278</td>\n",
       "      <td>55.001518</td>\n",
       "      <td>9.265532</td>\n",
       "      <td>447.647278</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>-16653.335833</td>\n",
       "      <td>-378483.772517</td>\n",
       "      <td>-16948.151452</td>\n",
       "      <td>pinball_loss</td>\n",
       "      <td>13.325348</td>\n",
       "      <td>2.318067</td>\n",
       "      <td>121.642115</td>\n",
       "      <td>13.325348</td>\n",
       "      <td>2.318067</td>\n",
       "      <td>121.642115</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestMSE_BAG_L1</td>\n",
       "      <td>-17089.100234</td>\n",
       "      <td>-382193.531424</td>\n",
       "      <td>-17404.721281</td>\n",
       "      <td>pinball_loss</td>\n",
       "      <td>175.570140</td>\n",
       "      <td>69.232747</td>\n",
       "      <td>1943.951175</td>\n",
       "      <td>175.570140</td>\n",
       "      <td>69.232747</td>\n",
       "      <td>1943.951175</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model    score_test        winkler     score_val  \\\n",
       "0     WeightedEnsemble_L2 -14835.534623 -333325.959380 -15137.935314   \n",
       "1     WeightedEnsemble_L3 -14836.838373 -333404.184288 -15137.935314   \n",
       "2       LightGBMXT_BAG_L1 -14961.281246 -340636.465662 -15450.075030   \n",
       "3         LightGBM_BAG_L1 -16653.335833 -378483.772517 -16948.151452   \n",
       "4  RandomForestMSE_BAG_L1 -17089.100234 -382193.531424 -17404.721281   \n",
       "\n",
       "    eval_metric  pred_time_test  pred_time_val     fit_time  \\\n",
       "0  pinball_loss      243.903204      80.823204  2513.693185   \n",
       "1  pinball_loss      243.900194      80.823108  2513.658417   \n",
       "2  pinball_loss       55.001518       9.265532   447.647278   \n",
       "3  pinball_loss       13.325348       2.318067   121.642115   \n",
       "4  pinball_loss      175.570140      69.232747  1943.951175   \n",
       "\n",
       "   pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  \\\n",
       "0                 0.006198                0.006859           0.452617   \n",
       "1                 0.003188                0.006763           0.417849   \n",
       "2                55.001518                9.265532         447.647278   \n",
       "3                13.325348                2.318067         121.642115   \n",
       "4               175.570140               69.232747        1943.951175   \n",
       "\n",
       "   stack_level  can_infer  fit_order  \n",
       "0            2       True          4  \n",
       "1            3       True          5  \n",
       "2            1       True          1  \n",
       "3            1       True          2  \n",
       "4            1       True          3  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(val, extra_metrics=[winkler], silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b0d7fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: data/test.csv | Columns = 46 / 46 | Rows = 200000 -> 200000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.50</th>\n",
       "      <th>0.95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>823002.312500</td>\n",
       "      <td>920490.37500</td>\n",
       "      <td>1.044536e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>490361.781250</td>\n",
       "      <td>631832.43750</td>\n",
       "      <td>7.946559e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>430205.218750</td>\n",
       "      <td>523137.53125</td>\n",
       "      <td>7.619690e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>296039.156250</td>\n",
       "      <td>354677.09375</td>\n",
       "      <td>4.497887e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>375201.218750</td>\n",
       "      <td>489386.68750</td>\n",
       "      <td>7.578192e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>228320.812500</td>\n",
       "      <td>287843.96875</td>\n",
       "      <td>3.714809e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>256219.359375</td>\n",
       "      <td>300612.15625</td>\n",
       "      <td>3.850549e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>376456.968750</td>\n",
       "      <td>432456.87500</td>\n",
       "      <td>4.994812e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>471460.781250</td>\n",
       "      <td>518472.78125</td>\n",
       "      <td>6.049948e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>477266.562500</td>\n",
       "      <td>575563.06250</td>\n",
       "      <td>6.586857e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0.05          0.50          0.95\n",
       "0       823002.312500  920490.37500  1.044536e+06\n",
       "1       490361.781250  631832.43750  7.946559e+05\n",
       "2       430205.218750  523137.53125  7.619690e+05\n",
       "3       296039.156250  354677.09375  4.497887e+05\n",
       "4       375201.218750  489386.68750  7.578192e+05\n",
       "...               ...           ...           ...\n",
       "199995  228320.812500  287843.96875  3.714809e+05\n",
       "199996  256219.359375  300612.15625  3.850549e+05\n",
       "199997  376456.968750  432456.87500  4.994812e+05\n",
       "199998  471460.781250  518472.78125  6.049948e+05\n",
       "199999  477266.562500  575563.06250  6.586857e+05\n",
       "\n",
       "[200000 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = TabularDataset('data/test.csv')\n",
    "test_predictions = predictor.predict(test)\n",
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac890cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('data/sample_submission.csv')\n",
    "sub['pi_lower'] = test_predictions[0.05]\n",
    "sub['pi_upper'] = test_predictions[0.95]\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prediction_interval_comp_II-house_price",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
